{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the performance of the model in the valid dataset \n",
    "Run the following command, you can see the performance of the model in the test set in the ./submission/ directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --config=\"cfgs/fishnet150-32.yaml\" --resume checkpoints/fishnet150_bs32/_15_best.pth.tar --val True --val-save True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --config=\"cfgs/fishnet150-32.yaml\" --resume checkpoints/fishnet150_bs32/_51_best.pth.tar --val True --val-save True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --config=\"cfgs/fishnet150-32.yaml\" --resume checkpoints/fishnet150_bs32/_10_best.pth.tar --val True --val-save True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --config=\"cfgs/FeatherNet54-32.yaml\" --resume checkpoints/FeatherNet54/_40_best.pth.tar --val True --val-save True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python main.py --config=\"cfgs/FeatherNet54-se-64.yaml\" --resume checkpoints/FeatherNet54-se/_68_best.pth.tar --val True --val-save True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --config=\"cfgs/mobilenetv2.yaml\" --resume checkpoints/mobilenetv2_bs32/_4_best.pth.tar --val True --val-save True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --config=\"cfgs/mobilenetv2.yaml\" --resume checkpoints/mobilenetv2_bs32/_5.pth.tar --val True --val-save True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --config=\"cfgs/mobilenetv2.yaml\" --resume ./checkpoints/mobilenetv2_bs32/_6.pth.tar --val True --val-save True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --config=\"cfgs/MobileLiteNetA-32.yaml\" --resume ./checkpoints/mobilelitenetA_bs32/_50_best.pth.tar --val True --val-save True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!python main.py --config=\"cfgs/MobileLiteNetB-32.yaml\" --resume ./checkpoints/mobilelitenetB_bs32/_47_best.pth.tar --val True --val-save True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split the predicted scores from each submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitscore(file_dir):\n",
    "    score = []\n",
    "    Prefix_str = []\n",
    "    f = open(file_dir)\n",
    "    for line in f:\n",
    "        s =line.split()\n",
    "        score.append(float(s[-1]))\n",
    "        s = s[0] + ' ' + s[1] + ' ' + s[2] + ' '\n",
    "        Prefix_str.append(s)\n",
    "    return score,Prefix_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect all predicted scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.238889e-05\n"
     ]
    }
   ],
   "source": [
    "file_dir1='submission/2019-01-28_15:45:05_fishnet150_52_submission.txt'\n",
    "score1,Prefix_str = splitscore(file_dir1)\n",
    "file_dir2 = 'submission/2019-02-13_15:22:05_FeatherNet54-se_69_submission.txt'\n",
    "score2,Prefix_str = splitscore(file_dir2)\n",
    "# print(Prefix_str[1])\n",
    "file_dir3 = 'submission/2019-03-01_22:25:43_fishnet150_27_submission.txt'\n",
    "score3,Prefix_str = splitscore(file_dir3)\n",
    "# \n",
    "file_dir4 = 'submission/2019-02-13_13:30:12_FeatherNet54_41_submission.txt'\n",
    "score4,Prefix_str = splitscore(file_dir4)\n",
    "# \n",
    "file_dir5 = 'submission/2019-02-13_14:13:43_fishnet150_16_submission.txt'\n",
    "score5,Prefix_str = splitscore(file_dir5)\n",
    "\n",
    "file_dir6 = 'submission/2019-02-16_19:31:04_moilenetv2_5_submission.txt'\n",
    "score6,Prefix_str = splitscore(file_dir6)\n",
    "file_dir7 = 'submission/2019-02-16_19:30:02_moilenetv2_7_submission.txt'\n",
    "score7,Prefix_str = splitscore(file_dir7)\n",
    "file_dir8 = 'submission/2019-02-16_19:28:47_moilenetv2_6_submission.txt'\n",
    "score8,Prefix_str = splitscore(file_dir8)\n",
    "\n",
    "\n",
    "file_dir9 = 'submission/2019-03-01_17:10:11_mobilelitenetB_48_submission.txt'\n",
    "score9,Prefix_str = splitscore(file_dir9)\n",
    "file_dir10 = 'submission/2019-03-01_17:38:27_mobilelitenetA_51_submission.txt'\n",
    "score10,Prefix_str = splitscore(file_dir10)\n",
    "\n",
    "# scores =[score1,score2,score3,score4,score5,score6,score7,score8,score9]\n",
    "scores = [score1,score2,score3,score4,score5,score6,score7,score8,score9,score10]\n",
    "print(scores[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get real labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9608"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_ensembled_file_dir='data/val_label.txt'\n",
    "real_scores,Prefix_str = splitscore(submission_ensembled_file_dir)\n",
    "len(real_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Average(lst): \n",
    "    return sum(lst) / len(lst) \n",
    "def fecth_ensembled_score(scores, threshold):\n",
    "    ensembled_score  = []\n",
    "    for i in range(len(score1)):\n",
    "        line_socres = [scores[j][i] for j in range(len(scores))]\n",
    "        mean_socre = Average(line_socres)\n",
    "        if mean_socre > threshold:\n",
    "            ensembled_score.append(max(line_socres))\n",
    "        else:\n",
    "            ensembled_score.append(min(line_socres))\n",
    "    return ensembled_score\n",
    "## \n",
    "def num_err(ensembled_score,threshold,real_scores):            \n",
    "    count = 0\n",
    "    for i in range(len(real_scores)):\n",
    "        if real_scores[i] == (ensembled_score[i]>0.5):\n",
    "            pass\n",
    "        else:\n",
    "            count = count + 1\n",
    "    if count < 5:\n",
    "        print('threshold: {:.3f} num_errors is {}'.format(threshold,count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    threshold = i / 100\n",
    "    ensembled_score = fecth_ensembled_score(scores, threshold)\n",
    "    num_err(ensembled_score,threshold,real_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the appropriate threshold to generate the final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_ensembled_file_dir='submission/submission_0.53.txt'\n",
    "ensembled_file = open(submission_ensembled_file_dir,'a')\n",
    "ensembled_score = fecth_ensembled_score(scores, 0.53)\n",
    "for i in range(len(ensembled_score)):\n",
    "    ensembled_file.write(Prefix_str[i]+str(ensembled_score[i])+'\\n')\n",
    "ensembled_file.close()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
